[2025-01-30 19:07:37,785] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-30 19:07:37,798] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-30 19:07:37,806] INFO: common: created directory at: artifacts]
[2025-01-30 19:07:40,173] INFO: common: created directory at: artifacts/data_ingestion]
[2025-01-30 19:07:51,717] INFO: 1434958058: artifacts/data_ingestion/data.zip download! with following info: 
Connection: close
Content-Length: 7903594
Cache-Control: max-age=300
Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'; sandbox
Content-Type: application/zip
ETag: "dbc016a060da18070593b83afff580c9b300f0b6ea4147a7988433e04df246ca"
Strict-Transport-Security: max-age=31536000
X-Content-Type-Options: nosniff
X-Frame-Options: deny
X-XSS-Protection: 1; mode=block
X-GitHub-Request-Id: DCF7:3645A7:28E21E:382765:679B80A6
Accept-Ranges: bytes
Date: Thu, 30 Jan 2025 13:37:45 GMT
Via: 1.1 varnish
X-Served-By: cache-bom4735-BOM
X-Cache: MISS
X-Cache-Hits: 0
X-Timer: S1738244263.353906,VS0,VE1756
Vary: Authorization,Accept-Encoding,Origin
Access-Control-Allow-Origin: *
Cross-Origin-Resource-Policy: cross-origin
X-Fastly-Request-ID: 590a5e37f0f0cb1b7711115cfe6e3af49b875906
Expires: Thu, 30 Jan 2025 13:42:45 GMT
Source-Age: 1

]
[2025-01-30 19:32:39,695] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-01-30 19:32:39,701] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-30 19:32:39,710] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-30 19:32:39,720] INFO: common: created directory at: artifacts]
[2025-01-30 19:32:39,720] INFO: common: created directory at: artifacts/data_ingestion]
[2025-01-30 19:32:39,720] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-01-30 19:32:41,737] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-01-30 20:01:43,829] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-30 20:01:43,839] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-30 20:01:43,839] INFO: common: created directory at: artifacts]
[2025-01-30 20:23:04,704] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-30 20:23:04,713] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-30 20:23:04,718] INFO: common: created directory at: artifacts]
[2025-01-30 20:23:04,729] INFO: common: created directory at: artifacts/data_validation]
[2025-01-30 20:25:10,883] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-30 20:25:10,893] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-30 20:25:10,898] INFO: common: created directory at: artifacts]
[2025-01-30 20:25:10,903] INFO: common: created directory at: artifacts/data_validation]
[2025-01-31 10:10:05,936] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-01-31 10:10:05,952] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-31 10:10:05,956] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-31 10:10:05,957] INFO: common: created directory at: artifacts]
[2025-01-31 10:10:05,959] INFO: common: created directory at: artifacts/data_ingestion]
[2025-01-31 10:10:05,960] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-01-31 10:10:07,799] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-01-31 10:10:07,801] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-01-31 10:10:07,804] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-31 10:10:07,805] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-31 10:10:07,806] INFO: common: created directory at: artifacts]
[2025-01-31 10:10:07,809] INFO: common: created directory at: artifacts/data_validation]
[2025-01-31 10:10:07,821] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-01-31 10:32:57,332] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-01-31 10:32:57,365] INFO: common: yaml file: params.yaml loaded successfully]
[2025-01-31 10:32:57,368] INFO: common: created directory at: artifacts]
[2025-01-31 10:32:57,371] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-01 18:28:23,784] INFO: config: PyTorch version 2.4.0 available.]
[2025-02-01 18:28:23,877] INFO: config: Polars version 1.5.0 available.]
[2025-02-01 18:28:23,877] INFO: config: TensorFlow version 2.18.0 available.]
[2025-02-01 18:37:58,324] INFO: config: PyTorch version 2.6.0+cpu available.]
[2025-02-01 18:37:58,332] INFO: config: Polars version 1.5.0 available.]
[2025-02-01 18:37:58,337] INFO: config: TensorFlow version 2.18.0 available.]
[2025-02-01 18:37:59,034] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-01 18:38:01,409] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-01 18:38:01,461] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-01 18:38:01,469] INFO: common: created directory at: artifacts]
[2025-02-01 18:38:01,469] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-01 18:38:01,477] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-01 18:38:03,504] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-01 18:38:03,512] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-01 18:38:03,512] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-01 18:38:03,520] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-01 18:38:03,520] INFO: common: created directory at: artifacts]
[2025-02-01 18:38:03,528] INFO: common: created directory at: artifacts/data_validation]
[2025-02-01 18:38:03,536] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-01 18:38:03,536] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-01 18:38:03,560] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-01 18:38:03,568] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-01 18:38:03,568] INFO: common: created directory at: artifacts]
[2025-02-01 18:38:03,568] ERROR: main: 'ConfigurationManager' object has no attribute 'get_data_transformation_config']
Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "e:\textinsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 12, in main
    data_transformation_config = config.get_data_transformation_config()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ConfigurationManager' object has no attribute 'get_data_transformation_config'. Did you mean: 'get_data_validation_config'?
[2025-02-02 11:12:01,569] INFO: config: Polars version 1.5.0 available.]
[2025-02-02 11:12:01,574] INFO: config: TensorFlow version 2.18.0 available.]
[2025-02-02 11:12:02,285] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-02 11:12:02,344] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:12:02,352] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:12:02,363] INFO: common: created directory at: artifacts]
[2025-02-02 11:12:02,366] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-02 11:12:02,366] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-02 11:12:03,195] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-02 11:12:03,195] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-02 11:12:03,195] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:12:03,195] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:12:03,195] INFO: common: created directory at: artifacts]
[2025-02-02 11:12:03,210] INFO: common: created directory at: artifacts/data_validation]
[2025-02-02 11:12:03,224] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-02 11:12:03,224] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-02 11:12:03,233] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:12:03,239] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:12:03,239] INFO: common: created directory at: artifacts]
[2025-02-02 11:12:03,239] ERROR: main: 'ConfigurationManager' object has no attribute 'get_data_transformation_config']
Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "e:\textinsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 12, in main
    data_transformation_config = config.get_data_transformation_config()
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'ConfigurationManager' object has no attribute 'get_data_transformation_config'. Did you mean: 'get_data_validation_config'?
[2025-02-02 11:14:36,157] INFO: config: Polars version 1.5.0 available.]
[2025-02-02 11:14:36,161] INFO: config: TensorFlow version 2.18.0 available.]
[2025-02-02 11:14:37,158] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-02 11:14:37,214] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:14:37,214] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:14:37,214] INFO: common: created directory at: artifacts]
[2025-02-02 11:14:37,214] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-02 11:14:37,214] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-02 11:14:38,644] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-02 11:14:38,644] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-02 11:14:38,652] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:14:38,654] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:14:38,657] INFO: common: created directory at: artifacts]
[2025-02-02 11:14:38,657] INFO: common: created directory at: artifacts/data_validation]
[2025-02-02 11:14:38,672] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-02 11:14:38,672] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-02 11:14:38,680] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:14:38,688] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:14:38,688] INFO: common: created directory at: artifacts]
[2025-02-02 11:14:38,693] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-02 11:14:39,206] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1496, in extract_vocab_merges_from_model
    from tiktoken.load import load_tiktoken_bpe
ModuleNotFoundError: No module named 'tiktoken'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1498, in extract_vocab_merges_from_model
    raise ValueError(
ValueError: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "e:\textinsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "e:\textinsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\LENOVO\AppData\Local\Programs\Python\Python312\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-02 11:16:04,684] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-02 11:16:08,554] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-02 11:16:08,564] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-02 11:16:08,567] INFO: common: created directory at: artifacts]
[2025-02-02 11:16:08,567] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 07:58:23,548] INFO: config: PyTorch version 2.6.0+cpu available.]
[2025-02-04 07:58:23,616] INFO: config: Polars version 1.5.0 available.]
[2025-02-04 07:58:23,631] INFO: config: TensorFlow version 2.18.0 available.]
[2025-02-04 08:40:19,677] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 08:40:19,717] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 08:40:19,757] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 08:40:19,757] INFO: common: created directory at: artifacts]
[2025-02-04 08:40:19,757] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 08:40:19,767] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 08:40:20,107] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 08:40:20,107] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 08:40:20,117] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 08:40:20,117] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 08:40:20,117] INFO: common: created directory at: artifacts]
[2025-02-04 08:40:20,117] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 08:40:20,137] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 08:40:20,137] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 08:40:20,146] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 08:40:20,155] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 08:40:20,157] INFO: common: created directory at: artifacts]
[2025-02-04 08:40:20,157] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 08:40:20,727] ERROR: main: 
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1496, in extract_vocab_merges_from_model
    from tiktoken.load import load_tiktoken_bpe
ModuleNotFoundError: No module named 'tiktoken'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1498, in extract_vocab_merges_from_model
    raise ValueError(
ValueError: `tiktoken` is required to read a `tiktoken` file. Install it with `pip install tiktoken`.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2277, in _from_pretrained
    except import_protobuf_decode_error():
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 87, in import_protobuf_decode_error
    raise ImportError(PROTOBUF_IMPORT_ERROR.format(error_message))
ImportError: 
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

[2025-02-04 09:08:00,478] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 09:08:00,500] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:08:00,515] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:08:00,517] INFO: common: created directory at: artifacts]
[2025-02-04 09:08:00,517] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 09:08:00,518] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 09:08:00,819] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 09:08:00,819] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 09:08:00,819] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:08:00,831] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:08:00,832] INFO: common: created directory at: artifacts]
[2025-02-04 09:08:00,834] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 09:08:00,836] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 09:08:00,836] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 09:08:00,848] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:08:00,855] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:08:00,856] INFO: common: created directory at: artifacts]
[2025-02-04 09:08:00,858] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 09:08:01,446] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 09:15:12,199] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 09:15:12,199] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:15:12,199] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:15:12,199] INFO: common: created directory at: artifacts]
[2025-02-04 09:15:12,212] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 09:15:12,214] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 09:15:12,415] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 09:15:12,415] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 09:15:12,430] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:15:12,436] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:15:12,437] INFO: common: created directory at: artifacts]
[2025-02-04 09:15:12,441] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 09:15:12,448] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 09:15:12,449] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 09:15:12,462] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:15:12,465] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:15:12,466] INFO: common: created directory at: artifacts]
[2025-02-04 09:15:12,466] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 09:15:12,865] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 09:17:55,539] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 09:17:55,655] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:17:56,832] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:17:56,854] INFO: common: created directory at: artifacts]
[2025-02-04 09:17:56,855] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 09:17:56,856] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 09:18:00,668] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 09:18:00,670] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 09:18:00,681] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:18:00,744] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:18:01,036] INFO: common: created directory at: artifacts]
[2025-02-04 09:18:01,133] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 09:18:01,164] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 09:18:01,248] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 09:18:01,280] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:18:01,354] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:18:01,382] INFO: common: created directory at: artifacts]
[2025-02-04 09:18:01,491] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 09:18:02,259] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 09:28:50,091] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 09:28:50,118] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:28:50,172] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:28:50,186] INFO: common: created directory at: artifacts]
[2025-02-04 09:28:50,188] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 09:28:50,189] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 09:28:52,437] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 09:28:52,440] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 09:28:52,446] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:28:52,448] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:28:52,449] INFO: common: created directory at: artifacts]
[2025-02-04 09:28:52,450] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 09:28:52,455] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 09:28:52,457] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 09:28:52,466] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 09:28:52,467] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 09:28:52,468] INFO: common: created directory at: artifacts]
[2025-02-04 09:28:52,469] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 09:28:53,077] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 14:30:21,851] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 14:30:21,923] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:30:21,987] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:30:22,003] INFO: common: created directory at: artifacts]
[2025-02-04 14:30:22,003] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 14:30:22,003] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 14:30:22,483] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 14:30:22,715] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 14:30:22,875] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:30:23,043] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:30:23,115] INFO: common: created directory at: artifacts]
[2025-02-04 14:30:23,155] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 14:30:23,235] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 14:30:23,323] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 14:30:23,411] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:30:23,531] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:30:23,627] INFO: common: created directory at: artifacts]
[2025-02-04 14:30:23,627] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 14:30:24,791] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 14:40:28,377] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 14:40:28,377] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:40:28,377] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:40:28,377] INFO: common: created directory at: artifacts]
[2025-02-04 14:40:28,377] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 14:40:28,377] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 14:40:28,617] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 14:40:28,617] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 14:40:28,617] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:40:28,625] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:40:28,625] INFO: common: created directory at: artifacts]
[2025-02-04 14:40:28,625] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 14:40:28,625] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 14:40:28,625] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 14:40:28,633] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:40:28,641] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:40:28,649] INFO: common: created directory at: artifacts]
[2025-02-04 14:40:28,649] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 14:40:29,161] ERROR: main: Conversion from Tiktoken failed: 'NoneType' object has no attribute 'encode'
Available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1652, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1655, in convert_slow_tokenizer
    raise ValueError(
ValueError: Conversion from Tiktoken failed: 'NoneType' object has no attribute 'encode'
Available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 14:46:21,288] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 14:46:21,288] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:46:21,296] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:46:21,296] INFO: common: created directory at: artifacts]
[2025-02-04 14:46:21,296] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 14:46:21,296] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 14:46:21,496] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 14:46:21,504] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 14:46:21,504] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:46:21,504] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:46:21,504] INFO: common: created directory at: artifacts]
[2025-02-04 14:46:21,504] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 14:46:21,512] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 14:46:21,520] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 14:46:21,520] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:46:21,528] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:46:21,528] INFO: common: created directory at: artifacts]
[2025-02-04 14:46:21,528] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 14:46:22,008] ERROR: main: Conversion from Tiktoken failed: 'NoneType' object has no attribute 'encode'
Available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1655, in convert_slow_tokenizer
    return tik_converter.converted()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1660, in convert_slow_tokenizer
    raise ValueError(
ValueError: Conversion from Tiktoken failed: 'NoneType' object has no attribute 'encode'
Available slow->fast converters: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 14:49:21,396] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 14:49:21,404] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:49:21,404] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:49:21,404] INFO: common: created directory at: artifacts]
[2025-02-04 14:49:21,404] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 14:49:21,404] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 14:49:21,692] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 14:49:21,692] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 14:49:21,700] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:49:21,700] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:49:21,708] INFO: common: created directory at: artifacts]
[2025-02-04 14:49:21,708] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 14:49:21,716] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 14:49:21,716] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 14:49:21,716] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 14:49:21,724] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 14:49:21,724] INFO: common: created directory at: artifacts]
[2025-02-04 14:49:21,724] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 14:49:22,517] ERROR: main: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']]
Traceback (most recent call last):
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1636, in convert_slow_tokenizer
    ).converted()
      ^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1533, in converted
    tokenizer = self.tokenizer()
                ^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1526, in tokenizer
    vocab_scores, merges = self.extract_vocab_merges_from_model(self.vocab_file)
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1502, in extract_vocab_merges_from_model
    bpe_ranks = load_tiktoken_bpe(tiktoken_url)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 144, in load_tiktoken_bpe
    contents = read_file_cached(tiktoken_bpe_file, expected_hash)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\tiktoken\load.py", line 48, in read_file_cached
    cache_key = hashlib.sha1(blobpath.encode()).hexdigest()
                             ^^^^^^^^^^^^^^^
AttributeError: 'NoneType' object has no attribute 'encode'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 13, in main
    data_transformation = DataTransformation(config=data_transformation_config)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 12, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(config.tokenizer_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\auto\tokenization_auto.py", line 953, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2036, in from_pretrained
    return cls._from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_base.py", line 2276, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\models\pegasus\tokenization_pegasus_fast.py", line 136, in __init__
    super().__init__(
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\tokenization_utils_fast.py", line 139, in __init__
    fast_tokenizer = convert_slow_tokenizer(self, from_tiktoken=True)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\transformers\convert_slow_tokenizer.py", line 1638, in convert_slow_tokenizer
    raise ValueError(
ValueError: Converting from Tiktoken failed, if a converter for SentencePiece is available, provide a model path with a SentencePiece tokenizer.model file.Currently available slow->fast convertors: ['AlbertTokenizer', 'BartTokenizer', 'BarthezTokenizer', 'BertTokenizer', 'BigBirdTokenizer', 'BlenderbotTokenizer', 'CamembertTokenizer', 'CLIPTokenizer', 'CodeGenTokenizer', 'ConvBertTokenizer', 'DebertaTokenizer', 'DebertaV2Tokenizer', 'DistilBertTokenizer', 'DPRReaderTokenizer', 'DPRQuestionEncoderTokenizer', 'DPRContextEncoderTokenizer', 'ElectraTokenizer', 'FNetTokenizer', 'FunnelTokenizer', 'GPT2Tokenizer', 'HerbertTokenizer', 'LayoutLMTokenizer', 'LayoutLMv2Tokenizer', 'LayoutLMv3Tokenizer', 'LayoutXLMTokenizer', 'LongformerTokenizer', 'LEDTokenizer', 'LxmertTokenizer', 'MarkupLMTokenizer', 'MBartTokenizer', 'MBart50Tokenizer', 'MPNetTokenizer', 'MobileBertTokenizer', 'MvpTokenizer', 'NllbTokenizer', 'OpenAIGPTTokenizer', 'PegasusTokenizer', 'Qwen2Tokenizer', 'RealmTokenizer', 'ReformerTokenizer', 'RemBertTokenizer', 'RetriBertTokenizer', 'RobertaTokenizer', 'RoFormerTokenizer', 'SeamlessM4TTokenizer', 'SqueezeBertTokenizer', 'T5Tokenizer', 'UdopTokenizer', 'WhisperTokenizer', 'XLMRobertaTokenizer', 'XLNetTokenizer', 'SplinterTokenizer', 'XGLMTokenizer', 'LlamaTokenizer', 'CodeLlamaTokenizer', 'GemmaTokenizer', 'Phi3Tokenizer']
[2025-02-04 15:53:00,043] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-04 15:53:10,574] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 15:53:10,600] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:10,606] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:10,614] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:53:10,615] INFO: common: created directory at: artifacts]
[2025-02-04 15:53:10,615] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 15:53:10,616] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 15:53:10,617] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 15:53:10,653] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 15:53:10,972] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 15:53:10,973] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 15:53:10,979] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:10,981] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:53:10,986] INFO: common: created directory at: artifacts]
[2025-02-04 15:53:10,989] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 15:53:10,992] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 15:53:10,996] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 15:53:11,001] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 15:53:11,012] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:11,015] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:11,015] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:53:11,017] INFO: common: created directory at: artifacts]
[2025-02-04 15:53:11,018] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:53:11,019] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 15:53:11,023] INFO: common: created directory at: artifacts]
[2025-02-04 15:53:11,026] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 15:53:11,085] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 15:53:11,088] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 15:53:11,095] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:53:11,109] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:53:11,112] INFO: common: created directory at: artifacts]
[2025-02-04 15:53:11,116] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 15:53:34,469] ERROR: main: Tried reading schema message, was null or length 0]
Traceback (most recent call last):
  File "E:\TextInsight\main.py", line 36, in <module>
    data_transformation.main()
  File "E:\TextInsight\src\TextInsight\pipeline\stage_03_data_transformation.py", line 14, in main
    data_transformation.convert()
  File "E:\TextInsight\src\TextInsight\components\data_transformation.py", line 31, in convert
    dataset_samsum_pt = dataset_samsum.map(self.convert_examples_to_features, batched = True)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\dataset_dict.py", line 887, in map
    k: dataset.map(
       ^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\arrow_dataset.py", line 560, in wrapper
    out: Union["Dataset", "DatasetDict"] = func(self, *args, **kwargs)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\arrow_dataset.py", line 3073, in map
    for rank, done, content in Dataset._map_single(**dataset_kwargs):
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\arrow_dataset.py", line 3531, in _map_single
    yield rank, True, Dataset.from_file(cache_file_name, info=info, split=shard.split)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\arrow_dataset.py", line 740, in from_file
    table = ArrowReader.read_table(filename, in_memory=in_memory)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\arrow_reader.py", line 329, in read_table
    return table_cls.from_file(filename)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\table.py", line 1017, in from_file
    table = _memory_mapped_arrow_table_from_file(filename)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\table.py", line 63, in _memory_mapped_arrow_table_from_file
    opened_stream = _memory_mapped_record_batch_reader_from_file(filename)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\datasets\table.py", line 49, in _memory_mapped_record_batch_reader_from_file
    return pa.ipc.open_stream(memory_mapped_stream)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\pyarrow\ipc.py", line 190, in open_stream
    return RecordBatchStreamReader(source, options=options,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\TextInsight\myenv\Lib\site-packages\pyarrow\ipc.py", line 52, in __init__
    self._open(source, options=options, memory_pool=memory_pool)
  File "pyarrow\\ipc.pxi", line 1006, in pyarrow.lib._RecordBatchStreamReader._open
  File "pyarrow\\error.pxi", line 155, in pyarrow.lib.pyarrow_internal_check_status
  File "pyarrow\\error.pxi", line 92, in pyarrow.lib.check_status
pyarrow.lib.ArrowInvalid: Tried reading schema message, was null or length 0
[2025-02-04 15:53:36,836] INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<

x==========x]
[2025-02-04 15:56:17,296] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-04 15:56:17,934] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 15:56:17,938] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:56:17,939] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:56:17,940] INFO: common: created directory at: artifacts]
[2025-02-04 15:56:17,941] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 15:56:17,942] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 15:56:18,411] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 15:56:18,413] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 15:56:18,418] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:56:18,420] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:56:18,449] INFO: common: created directory at: artifacts]
[2025-02-04 15:56:18,484] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 15:56:18,512] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 15:56:18,516] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 15:56:18,525] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 15:56:18,548] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 15:56:18,551] INFO: common: created directory at: artifacts]
[2025-02-04 15:56:18,558] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 15:56:21,332] INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<

x==========x]
[2025-02-04 20:03:20,326] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-04 20:03:35,539] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-04 20:03:35,554] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 20:03:35,576] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 20:03:35,577] INFO: common: created directory at: artifacts]
[2025-02-04 20:03:35,577] INFO: common: created directory at: artifacts/data_ingestion]
[2025-02-04 20:03:35,577] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-04 20:03:38,285] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-04 20:03:38,301] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-04 20:03:38,301] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 20:03:38,301] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 20:03:38,319] INFO: common: created directory at: artifacts]
[2025-02-04 20:03:38,319] INFO: common: created directory at: artifacts/data_validation]
[2025-02-04 20:03:38,325] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-04 20:03:38,325] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-04 20:03:38,337] INFO: common: yaml file: config\config.yaml loaded successfully]
[2025-02-04 20:03:38,337] INFO: common: yaml file: params.yaml loaded successfully]
[2025-02-04 20:03:38,345] INFO: common: created directory at: artifacts]
[2025-02-04 20:03:38,345] INFO: common: created directory at: artifacts/data_transformation]
[2025-02-04 20:03:44,902] INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<

x==========x]
[2025-02-04 21:12:23,548] INFO: fake_tensor: FakeTensor cache stats:]
[2025-02-04 21:12:23,581] INFO: fake_tensor:   cache_hits: 0]
[2025-02-04 21:12:23,581] INFO: fake_tensor:   cache_misses: 0]
[2025-02-04 21:17:53,209] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-04 21:30:37,079] INFO: fake_tensor: FakeTensor cache stats:]
[2025-02-04 21:30:37,112] INFO: fake_tensor:   cache_hits: 0]
[2025-02-04 21:30:37,112] INFO: fake_tensor:   cache_misses: 0]
[2025-02-05 16:05:12,004] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-05 16:05:12,019] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-05 16:05:12,025] INFO: common: Created directory at: artifacts]
[2025-02-05 16:05:12,027] INFO: common: Created directory at: artifacts/data_validation]
[2025-02-06 09:23:19,393] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-06 09:23:22,246] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 09:23:22,265] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 09:23:22,266] INFO: common: Created directory at: artifacts]
[2025-02-06 09:27:07,071] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 09:27:07,078] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 09:27:07,080] INFO: common: Created directory at: artifacts]
[2025-02-06 09:46:57,564] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 09:46:57,684] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 09:46:57,687] INFO: common: Created directory at: artifacts]
[2025-02-06 09:46:57,689] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-06 09:48:50,929] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-06 09:48:53,213] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 09:48:53,221] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 09:48:53,224] INFO: common: Created directory at: artifacts]
[2025-02-06 09:48:53,227] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-06 10:00:15,421] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 10:00:15,465] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 10:00:15,471] INFO: common: Created directory at: artifacts]
[2025-02-06 10:00:15,473] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-06 10:21:50,682] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 10:21:50,772] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 10:21:50,786] INFO: common: Created directory at: artifacts]
[2025-02-06 10:21:50,808] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-06 14:00:27,439] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-06 14:00:29,745] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-06 14:00:29,754] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-06 14:00:29,755] INFO: common: Created directory at: artifacts]
[2025-02-06 14:00:29,760] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-09 18:40:39,539] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-09 18:40:41,587] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-09 18:40:41,598] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-09 18:40:41,598] INFO: common: Created directory at: artifacts]
[2025-02-09 18:40:41,598] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-15 10:55:29,834] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 10:55:31,760] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 10:55:31,786] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 10:55:31,789] INFO: common: Created directory at: artifacts]
[2025-02-15 10:55:31,791] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-15 11:34:27,797] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 11:34:27,867] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 11:34:27,884] INFO: common: Created directory at: artifacts]
[2025-02-15 11:34:27,902] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-15 12:12:42,408] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 12:12:44,695] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 12:12:44,702] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 12:12:44,709] INFO: common: Created directory at: artifacts]
[2025-02-15 12:12:44,712] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-15 18:46:04,641] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 18:46:07,043] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 18:46:07,053] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 18:46:07,056] INFO: common: Created directory at: artifacts]
[2025-02-15 18:46:07,113] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 20:53:47,358] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 20:53:49,344] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 20:53:49,349] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 20:53:49,350] INFO: common: Created directory at: artifacts]
[2025-02-15 20:53:49,355] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 21:06:37,006] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 21:06:40,180] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 21:06:40,204] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 21:06:40,204] INFO: common: Created directory at: artifacts]
[2025-02-15 21:06:40,204] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 21:24:24,234] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 21:24:24,239] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 21:24:24,239] INFO: common: Created directory at: artifacts]
[2025-02-15 21:24:24,239] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 21:24:54,949] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 21:24:57,359] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 21:24:57,369] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 21:24:57,369] INFO: common: Created directory at: artifacts]
[2025-02-15 21:24:57,374] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 21:27:34,064] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 21:27:34,070] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 21:27:34,070] INFO: common: Created directory at: artifacts]
[2025-02-15 21:27:34,078] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 21:58:33,400] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 21:58:33,565] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 22:04:07,203] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 22:11:20,048] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-15 22:11:25,882] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-15 22:11:25,898] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:11:25,963] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:11:25,973] INFO: common: Created directory at: artifacts]
[2025-02-15 22:11:25,973] INFO: common: Created directory at: artifacts/data_ingestion]
[2025-02-15 22:11:25,978] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-15 22:11:26,373] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-15 22:11:26,383] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-15 22:11:26,383] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:11:26,391] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:11:26,391] INFO: common: Created directory at: artifacts]
[2025-02-15 22:11:26,391] INFO: common: Created directory at: artifacts/data_validation]
[2025-02-15 22:11:26,391] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-15 22:11:26,399] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-15 22:11:26,403] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:11:26,403] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:11:26,413] INFO: common: Created directory at: artifacts]
[2025-02-15 22:11:26,413] INFO: common: Created directory at: artifacts/data_transformation]
[2025-02-15 22:11:34,783] INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<

x==========x]
[2025-02-15 22:11:34,792] INFO: main: *******************]
[2025-02-15 22:11:34,792] INFO: main: >>>>>> stage Model Trainer stage started <<<<<<]
[2025-02-15 22:11:34,792] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:11:34,802] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:11:34,802] INFO: common: Created directory at: artifacts]
[2025-02-15 22:11:34,802] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-15 22:24:38,830] INFO: server: Started server process [11716]]
[2025-02-15 22:24:38,850] INFO: on: Waiting for application startup.]
[2025-02-15 22:24:38,859] INFO: on: Application startup complete.]
[2025-02-15 22:24:38,859] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-15 22:34:25,719] INFO: server: Shutting down]
[2025-02-15 22:34:25,829] INFO: on: Waiting for application shutdown.]
[2025-02-15 22:34:25,829] INFO: on: Application shutdown complete.]
[2025-02-15 22:34:25,829] INFO: server: Finished server process [11716]]
[2025-02-15 22:41:54,275] INFO: server: Started server process [13224]]
[2025-02-15 22:41:54,314] INFO: on: Waiting for application startup.]
[2025-02-15 22:41:54,320] INFO: on: Application startup complete.]
[2025-02-15 22:41:54,325] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-15 22:42:53,408] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:42:53,459] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:42:53,485] INFO: common: Created directory at: artifacts]
[2025-02-15 22:42:53,485] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 22:46:32,852] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:46:32,869] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:46:32,874] INFO: common: Created directory at: artifacts]
[2025-02-15 22:46:32,882] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 22:48:10,863] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-15 22:48:10,871] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-15 22:48:10,872] INFO: common: Created directory at: artifacts]
[2025-02-15 22:48:10,873] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-15 23:13:32,571] INFO: server: Shutting down]
[2025-02-15 23:13:32,690] INFO: on: Waiting for application shutdown.]
[2025-02-15 23:13:32,710] INFO: on: Application shutdown complete.]
[2025-02-15 23:13:32,760] INFO: server: Finished server process [13224]]
[2025-02-22 13:34:59,841] INFO: config: PyTorch version 2.6.0 available.]
[2025-02-22 13:35:24,937] INFO: main: >>>>>> stage Data Ingestion stage started <<<<<<]
[2025-02-22 13:35:24,979] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-22 13:35:25,030] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-22 13:35:25,034] INFO: common: Created directory at: artifacts]
[2025-02-22 13:35:25,035] INFO: common: Created directory at: artifacts/data_ingestion]
[2025-02-22 13:35:25,037] INFO: data_ingestion: File already exists of size: ~ 7718 KB]
[2025-02-22 13:35:25,450] INFO: main: >>>>>> stage Data Ingestion stage completed <<<<<<

x==========x]
[2025-02-22 13:35:25,451] INFO: main: >>>>>> stage Data Validation stage started <<<<<<]
[2025-02-22 13:35:25,455] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-22 13:35:25,466] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-22 13:35:25,467] INFO: common: Created directory at: artifacts]
[2025-02-22 13:35:25,468] INFO: common: Created directory at: artifacts/data_validation]
[2025-02-22 13:35:25,472] INFO: main: >>>>>> stage Data Validation stage completed <<<<<<

x==========x]
[2025-02-22 13:35:25,473] INFO: main: >>>>>> stage Data Transformation stage started <<<<<<]
[2025-02-22 13:35:25,487] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-22 13:35:25,491] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-22 13:35:25,493] INFO: common: Created directory at: artifacts]
[2025-02-22 13:35:25,501] INFO: common: Created directory at: artifacts/data_transformation]
[2025-02-22 13:35:42,763] INFO: main: >>>>>> stage Data Transformation stage completed <<<<<<

x==========x]
[2025-02-22 13:35:42,764] INFO: main: *******************]
[2025-02-22 13:35:42,765] INFO: main: >>>>>> stage Model Trainer stage started <<<<<<]
[2025-02-22 13:35:42,770] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-22 13:35:42,782] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-22 13:35:42,784] INFO: common: Created directory at: artifacts]
[2025-02-22 13:35:42,785] INFO: common: Created directory at: artifacts/model_trainer]
[2025-02-22 14:13:35,882] INFO: server: Started server process [14928]]
[2025-02-22 14:13:35,892] INFO: on: Waiting for application startup.]
[2025-02-22 14:13:35,894] INFO: on: Application startup complete.]
[2025-02-22 14:13:35,897] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-22 14:21:37,503] INFO: server: Shutting down]
[2025-02-22 14:21:37,611] INFO: on: Waiting for application shutdown.]
[2025-02-22 14:21:38,725] INFO: on: Application shutdown complete.]
[2025-02-22 14:21:38,743] INFO: server: Finished server process [14928]]
[2025-02-22 14:24:40,320] INFO: server: Started server process [8112]]
[2025-02-22 14:24:40,335] INFO: on: Waiting for application startup.]
[2025-02-22 14:24:40,339] INFO: on: Application startup complete.]
[2025-02-22 14:24:40,343] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-22 14:29:34,368] INFO: server: Shutting down]
[2025-02-22 14:29:34,488] INFO: on: Waiting for application shutdown.]
[2025-02-22 14:29:34,492] INFO: on: Application shutdown complete.]
[2025-02-22 14:29:34,494] INFO: server: Finished server process [8112]]
[2025-02-25 15:17:46,291] INFO: server: Started server process [7480]]
[2025-02-25 15:17:46,342] INFO: on: Waiting for application startup.]
[2025-02-25 15:17:46,344] INFO: on: Application startup complete.]
[2025-02-25 15:17:46,346] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-25 15:24:53,179] INFO: server: Shutting down]
[2025-02-25 15:24:53,294] INFO: on: Waiting for application shutdown.]
[2025-02-25 15:24:53,299] INFO: on: Application shutdown complete.]
[2025-02-25 15:24:53,299] INFO: server: Finished server process [7480]]
[2025-02-25 15:35:45,760] INFO: server: Started server process [16016]]
[2025-02-25 15:35:45,766] INFO: on: Waiting for application startup.]
[2025-02-25 15:35:45,766] INFO: on: Application startup complete.]
[2025-02-25 15:35:45,766] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-25 15:37:21,332] INFO: server: Shutting down]
[2025-02-25 15:37:21,439] INFO: on: Waiting for application shutdown.]
[2025-02-25 15:37:21,439] INFO: on: Application shutdown complete.]
[2025-02-25 15:37:21,439] INFO: server: Finished server process [16016]]
[2025-02-25 16:34:28,067] INFO: server: Started server process [16512]]
[2025-02-25 16:34:28,108] INFO: on: Waiting for application startup.]
[2025-02-25 16:34:28,108] INFO: on: Application startup complete.]
[2025-02-25 16:34:28,133] INFO: server: Uvicorn running on http://0.0.0.0:8080 (Press CTRL+C to quit)]
[2025-02-25 16:36:25,711] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-25 16:36:25,711] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-25 16:36:25,729] INFO: common: Created directory at: artifacts]
[2025-02-25 16:36:25,737] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-25 16:38:58,941] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-25 16:38:58,978] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-25 16:38:58,985] INFO: common: Created directory at: artifacts]
[2025-02-25 16:38:58,985] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-25 16:46:10,489] INFO: common: YAML file: E:\TextInsight\config\config.yaml loaded successfully]
[2025-02-25 16:46:10,515] INFO: common: YAML file: E:\TextInsight\params.yaml loaded successfully]
[2025-02-25 16:46:10,523] INFO: common: Created directory at: artifacts]
[2025-02-25 16:46:10,523] INFO: common: Created directory at: artifacts/model_evaluation]
[2025-02-25 16:56:12,235] INFO: server: Shutting down]
[2025-02-25 16:56:12,394] INFO: on: Waiting for application shutdown.]
[2025-02-25 16:56:12,436] INFO: on: Application shutdown complete.]
[2025-02-25 16:56:12,443] INFO: server: Finished server process [16512]]
